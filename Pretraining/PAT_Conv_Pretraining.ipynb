{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DLnvDDAvZcg"
      },
      "source": [
        "# PAT Conv Pretraining Notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luetswgMv_8y"
      },
      "source": [
        "Trained with Google TPU v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLBWYOLfN7Vt"
      },
      "source": [
        "#Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpupLYYoxvNH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3Gs2bFVn5ZMb"
      },
      "outputs": [],
      "source": [
        "# @title Importing\n",
        "\n",
        "#Installs\n",
        "!pip install pyarrow fastparquet\n",
        "\n",
        "# Packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "#from keras.layers.embeddings import Embedding\n",
        "from keras.metrics import AUC\n",
        "\n",
        "# Tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afsH2qmUxGQi"
      },
      "outputs": [],
      "source": [
        "#@title Random Seeds\n",
        "import random\n",
        "## SEEDS\n",
        "\n",
        "# Hard Code Random Seeds.\n",
        "r1 = 0\n",
        "r2 = 1\n",
        "\n",
        "# Set Random Seed\n",
        "random.seed(r1)\n",
        "tf.random.set_seed(r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "N4rQXYZcwz73"
      },
      "outputs": [],
      "source": [
        "#@title Connect to TPU\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Connect to the TPU cluster or fall back to CPU/GPU\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()  # Tries to connect to the TPU\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\n",
        "  devices = tf.config.list_logical_devices('TPU')\n",
        "  print('TPU devices:', devices)\n",
        "except ValueError:\n",
        "  print(\"Could not connect to TPU; using CPU/GPU strategy instead.\")\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "\n",
        "# Example computation using the strategy\n",
        "with strategy.scope():\n",
        "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "  @tf.function\n",
        "  def matmul_fn(x, y):\n",
        "    return tf.matmul(x, y)\n",
        "\n",
        "  z = strategy.run(matmul_fn, args=(a, b))\n",
        "\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6FAjx67HjgF"
      },
      "source": [
        "# Hyperparameters & Settings (Fill out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hgz3qjavw6xX"
      },
      "outputs": [],
      "source": [
        "# write where you want to save all your files\n",
        "## CHANGE ##\n",
        "root = \"/content/drive/MyDrive/ActigraphyTransformer/A-NEW/PAT Experiments /PAT Conv Pretraining/Encoders\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM4cghQbLMn9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Please Fill out Parameters Below\n",
        "\"\"\"\n",
        "## Model size\n",
        "# eg. [\"small\", \"medium\", \"large\", \"huge\"]\n",
        "size = \"small\"\n",
        "\n",
        "## Mask ratio\n",
        "# eg. [.25, .50, .75]\n",
        "mask_ratio = 0.90\n",
        "\n",
        "## Smoothing\n",
        "# eg. [True, False]\n",
        "smoothing = False\n",
        "\n",
        "## Loss Function\n",
        "# eg. [True, False], meaning MSE on only the masked portion or everything in the reconstruction\n",
        "mse_only_masked = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XOvJcK73CeT"
      },
      "outputs": [],
      "source": [
        "# Model naming\n",
        "mask_name = int(mask_ratio*100)\n",
        "\n",
        "name = f\"/conv_encoder_{size}_{mask_name}\"\n",
        "\n",
        "if smoothing == True:\n",
        "  name = f\"{name}_smoothed\"\n",
        "else:\n",
        "  name = f\"{name}_unsmoothed\"\n",
        "\n",
        "if mse_only_masked == True:\n",
        "  name = f\"{name}_mse_only_masked.h5\"\n",
        "else:\n",
        "  name = f\"{name}_mse_all.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4qslH7X3JKn"
      },
      "outputs": [],
      "source": [
        "print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ug9_cnGL0OT"
      },
      "source": [
        "# Hyperparameter Additional Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0rxwgR_HkrB"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Model Size\n",
        "\"\"\"\n",
        "## Model Size\n",
        "if size == \"small\":\n",
        "\n",
        "  patch_size = 18\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 6\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 1\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 6\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"medium\":\n",
        "\n",
        "  patch_size = 18\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 2\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"large\":\n",
        "\n",
        "  patch_size = 9\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 4\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"huge\":\n",
        "\n",
        "  patch_size = 5\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 8\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Eb0HHhsIUfM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "For Pretraining\n",
        "\"\"\"\n",
        "\n",
        "## Model Size\n",
        "if size == \"small\":\n",
        "\n",
        "  learning_rate = 0.001\n",
        "  early_stopping_patience = 250\n",
        "  reduce_lr_patience = 75\n",
        "  min_lr = 1e-4\n",
        "\n",
        "if size == \"medium\":\n",
        "\n",
        "  learning_rate = 0.001\n",
        "  early_stopping_patience = 250\n",
        "  reduce_lr_patience = 75\n",
        "  min_lr = 1e-4\n",
        "\n",
        "if size == \"large\":\n",
        "\n",
        "  learning_rate = 0.0001\n",
        "  early_stopping_patience = 500\n",
        "  reduce_lr_patience = 100\n",
        "  min_lr = 1e-5\n",
        "\n",
        "\n",
        "if size == \"huge\":\n",
        "\n",
        "  learning_rate = 0.00001\n",
        "  early_stopping_patience = 500\n",
        "  reduce_lr_patience = 100\n",
        "  min_lr = 1e-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHoK6hGwNJ6F"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Smoothing\n",
        "\"\"\"\n",
        "if smoothing == True:\n",
        "  data = pd.read_parquet('/content/drive/MyDrive/ActigraphyTransformer/A-NEW/Data Preprocessing/SelfSupervised Datasets/Smooth/[SelfSupervised][Smooth]WideSeqnActi_AndMeds_2013.parq')\n",
        "\n",
        "else:\n",
        "  data = pd.read_parquet('/content/drive/MyDrive/ActigraphyTransformer/A-NEW/Data Preprocessing/SelfSupervised Datasets/Raw/[SelfSupervised][Raw]WideSeqnActi_AndMeds_2013.parq')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye8xyruzvf68"
      },
      "source": [
        "# Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uzonweo6pYs"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First, split into train and temp (this temp will be split into validation and test)\n",
        "X_train, X_test = train_test_split(np.array(data), test_size=0.005, random_state=19, shuffle=True)\n",
        "\n",
        "\n",
        "# Reshape Train and Test\n",
        "n_participants_train = X_train.shape[0]\n",
        "n_participants_test = X_test.shape[0]\n",
        "n_timesteps = X_train.shape[1]\n",
        "n_features = 1\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((n_participants_train, n_timesteps, n_features))\n",
        "X_test = X_test.reshape((n_participants_test, n_timesteps, n_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2nSxPf9RBGs"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeMZYnkrRBOh"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gT_O4t9zhBs"
      },
      "source": [
        "# Autoencoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1wPwVXe2KYC"
      },
      "source": [
        "#MAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu9PeUxXlFUT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Modified Transformer Block to output attention weights with explicit layer names\n",
        "def TransformerBlock(embed_dim, num_heads, ff_dim, rate=0.1, name_prefix=\"encoder\"):\n",
        "    # Input\n",
        "    input_layer = layers.Input(shape=(None, embed_dim), name=f\"{name_prefix}_input\")\n",
        "    #Attention\n",
        "    attention_layer = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, name=f\"{name_prefix}_attention\")\n",
        "    attention_output, attention_weights = attention_layer(input_layer, input_layer, return_attention_scores=True)\n",
        "    attention_output = layers.Dropout(rate, name=f\"{name_prefix}_dropout\")(attention_output)\n",
        "    # Add + Norm\n",
        "    out1 = layers.LayerNormalization(epsilon=1e-6, name=f\"{name_prefix}_norm1\")(input_layer + attention_output)\n",
        "    # FF Network\n",
        "    ff_output = layers.Dense(ff_dim, activation=\"relu\", name=f\"{name_prefix}_ff1\")(out1)\n",
        "    ff_output = layers.Dense(embed_dim, name=f\"{name_prefix}_ff2\")(ff_output)\n",
        "    ff_output = layers.Dropout(rate, name=f\"{name_prefix}_dropout2\")(ff_output)\n",
        "    # Add + Norm\n",
        "    final_output = layers.LayerNormalization(epsilon=1e-6, name=f\"{name_prefix}_norm2\")(out1 + ff_output)\n",
        "    return models.Model(inputs=input_layer, outputs=[final_output, attention_weights], name=f\"{name_prefix}_transformer\")\n",
        "\n",
        "# Custom Layer to create and apply the mask for MAE\n",
        "class MaskLayer(layers.Layer):\n",
        "    def __init__(self, mask_ratio, embed_dim, **kwargs):\n",
        "        super(MaskLayer, self).__init__(**kwargs)\n",
        "        self.mask_ratio = mask_ratio\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.mask_token = self.add_weight(\n",
        "            shape=(1, 1, self.embed_dim),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='mask_token'\n",
        "        )\n",
        "\n",
        "    def call(self, patch_embeddings, positional_embeddings):\n",
        "        batch_size = tf.shape(patch_embeddings)[0]\n",
        "        num_patches = tf.shape(patch_embeddings)[1]\n",
        "\n",
        "        shuffled_indices = tf.random.shuffle(tf.range(num_patches))\n",
        "        num_masked = tf.cast(tf.math.round(self.mask_ratio * tf.cast(num_patches, tf.float32)), tf.int32)\n",
        "\n",
        "        masked_indices = shuffled_indices[:num_masked]\n",
        "        visible_indices = shuffled_indices[num_masked:]\n",
        "\n",
        "        visible_patches = tf.gather(patch_embeddings, indices=visible_indices, axis=1)\n",
        "        masked_patches = tf.gather(patch_embeddings, indices=masked_indices, axis=1)\n",
        "        visible_positional_embeddings = tf.gather(positional_embeddings, indices=visible_indices, axis=0)\n",
        "\n",
        "        return visible_patches, masked_patches, visible_positional_embeddings, shuffled_indices, masked_indices\n",
        "\n",
        "# Custom Layer to create mask tokens for the decoder\n",
        "class MaskTokenLayer(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MaskTokenLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, mask_token, masked_patches):\n",
        "        tiled_mask_tokens = tf.tile(mask_token, [tf.shape(masked_patches)[0], tf.shape(masked_patches)[1], 1])\n",
        "        return tiled_mask_tokens\n",
        "\n",
        "# Custom Layer to concatenate tensors\n",
        "class ConcatLayer(layers.Layer):\n",
        "    def __init__(self, axis, **kwargs):\n",
        "        super(ConcatLayer, self).__init__(**kwargs)\n",
        "        self.axis = axis\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.concat(inputs, axis=self.axis)\n",
        "\n",
        "# Unshuffling Layer to revert the shuffle applied during masking\n",
        "class UnshuffleLayer(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(UnshuffleLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, patches, shuffle_indices):\n",
        "        num_patches = tf.shape(shuffle_indices)[0]\n",
        "\n",
        "        reverse_indices = tf.scatter_nd(\n",
        "            tf.expand_dims(shuffle_indices, axis=-1),\n",
        "            tf.range(num_patches),\n",
        "            [num_patches]\n",
        "        )\n",
        "\n",
        "        unshuffled_patches = tf.gather(patches, indices=reverse_indices, axis=1)\n",
        "\n",
        "        return unshuffled_patches\n",
        "\n",
        "# Sine/Cosine positional embeddings\n",
        "def get_positional_embeddings(num_patches, embed_dim):\n",
        "    position = tf.range(num_patches, dtype=tf.float32)[:, tf.newaxis]\n",
        "    div_term = tf.exp(tf.range(0, embed_dim, 2, dtype=tf.float32) * (-tf.math.log(10000.0) / embed_dim))\n",
        "    pos_embeddings = tf.concat([tf.sin(position * div_term), tf.cos(position * div_term)], axis=-1)\n",
        "    return pos_embeddings\n",
        "\n",
        "# Custom Layer to calculate MSE only on masked portions\n",
        "class MaskedMSELayer(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MaskedMSELayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, y_true, y_pred, masked_indices, mse_only_masked):\n",
        "\n",
        "        if mse_only_masked:\n",
        "            y_true_flat = tf.reshape(y_true, [-1])\n",
        "            y_pred_flat = tf.reshape(y_pred, [-1])\n",
        "\n",
        "            y_true_masked = tf.gather(y_true_flat, masked_indices)\n",
        "            y_pred_masked = tf.gather(y_pred_flat, masked_indices)\n",
        "\n",
        "            mse_loss = tf.reduce_mean(tf.square(y_true_masked - y_pred_masked))\n",
        "        else:\n",
        "            mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "        return mse_loss\n",
        "\n",
        "# Model creation function\n",
        "def create_model(input_size=10080, patch_size=patch_size, embed_dim=embed_dim,\n",
        "                 encoder_num_heads=encoder_num_heads, encoder_ff_dim=encoder_ff_dim, encoder_num_layers=encoder_num_layers, encoder_rate=encoder_rate,\n",
        "                 decoder_num_heads=decoder_num_heads, decoder_ff_dim=decoder_ff_dim, decoder_num_layers=decoder_num_layers, decoder_rate=decoder_rate,\n",
        "                 mask_ratio=mask_ratio, mse_only_masked=mse_only_masked, return_attention=False):\n",
        "\n",
        "    num_patches = input_size // patch_size\n",
        "    inputs = layers.Input(shape=(input_size,), name=\"inputs\")\n",
        "    reshaped = layers.Reshape((num_patches, patch_size), name=\"reshape\")(inputs)\n",
        "\n",
        "    # Add a channel dimension: (num_patches, patch_size, 1)\n",
        "    patches_with_channel = layers.Reshape((num_patches, patch_size, 1), name=\"add_channel_dim\")(reshaped)\n",
        "\n",
        "    # Apply Conv1D to each patch individually using TimeDistributed\n",
        "    conv_layer = layers.TimeDistributed(\n",
        "        layers.Conv1D(\n",
        "            filters=embed_dim,\n",
        "            kernel_size=3,\n",
        "            padding='same',\n",
        "            activation='relu'\n",
        "        ),\n",
        "        name=\"conv1d_patch_embedding\"\n",
        "    )\n",
        "\n",
        "    # Output shape: (num_patches, patch_size, embed_dim)\n",
        "    conv_output = conv_layer(patches_with_channel)\n",
        "\n",
        "    # Pool over the patch dimension to get a fixed-size embedding per patch\n",
        "    pooling_layer = layers.TimeDistributed(\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        name=\"global_avg_pooling\"\n",
        "    )\n",
        "\n",
        "    # Output shape: (num_patches, embed_dim)\n",
        "    patch_embeddings = pooling_layer(conv_output)\n",
        "\n",
        "    positional_embeddings = get_positional_embeddings(num_patches, embed_dim)\n",
        "\n",
        "    mask_layer = MaskLayer(mask_ratio, embed_dim, name=\"mask_layer\")\n",
        "    visible_patches, masked_patches, visible_positional_embeddings, shuffle_indices, masked_indices = mask_layer(patch_embeddings, positional_embeddings)\n",
        "\n",
        "    x = visible_patches + visible_positional_embeddings\n",
        "    attention_weights = []\n",
        "\n",
        "    for i in range(encoder_num_layers):\n",
        "        x, weights = TransformerBlock(embed_dim, encoder_num_heads, encoder_ff_dim, encoder_rate, name_prefix=f\"encoder_layer_{i+1}\")(x)\n",
        "        if return_attention:\n",
        "            attention_weights.append(weights)\n",
        "\n",
        "    mask_token_layer = MaskTokenLayer(name=\"mask_token_layer\")\n",
        "    mask_tokens = mask_token_layer(mask_layer.mask_token, masked_patches)\n",
        "\n",
        "    decoder_input = ConcatLayer(axis=1, name=\"concat_layer\")([x, mask_tokens])\n",
        "\n",
        "    unshuffle_layer = UnshuffleLayer(name=\"unshuffle_layer\")\n",
        "    decoder_input_unshuffled = unshuffle_layer(decoder_input, shuffle_indices)\n",
        "\n",
        "    decoder_input_with_pos = decoder_input_unshuffled + positional_embeddings\n",
        "\n",
        "    y = decoder_input_with_pos\n",
        "    for i in range(decoder_num_layers):\n",
        "        y, _ = TransformerBlock(embed_dim, decoder_num_heads, encoder_ff_dim, decoder_rate, name_prefix=f\"decoder_layer_{i+1}\")(y)\n",
        "\n",
        "    outputs = layers.Dense(patch_size, activation='tanh', name=\"decoder_dense\")(y)\n",
        "    outputs = 2 * outputs #nothing above 2 standard deviations we'll just categorize as the same\n",
        "    outputs = layers.Reshape((input_size,), name=\"decoder_reshape\")(outputs)\n",
        "\n",
        "    masked_mse_layer = MaskedMSELayer(name=\"masked_mse_layer\")\n",
        "    loss = masked_mse_layer(inputs, outputs, masked_indices, mse_only_masked)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs, name=\"MAE_model\")\n",
        "    model.add_loss(loss)\n",
        "\n",
        "    if return_attention:\n",
        "        return models.Model(inputs=inputs, outputs=[outputs] + attention_weights, name=\"MAE_with_attention\")\n",
        "    else:\n",
        "        return model\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    model = create_model()\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "        learning_rate=learning_rate,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-07,\n",
        "        amsgrad=False))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNsm1XsL2wWq"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz_VsGkXeOJc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "\n",
        "# Define your custom callback\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, function, frequency):\n",
        "        super(CustomCallback, self).__init__()\n",
        "        self.function = function\n",
        "        self.frequency = frequency\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.frequency == 0:\n",
        "            self.function(epoch + 1, logs)\n",
        "\n",
        "# Define your custom function\n",
        "def my_custom_function(epoch, logs):\n",
        "    print(f\"\\n plotting.. output {epoch}\")\n",
        "\n",
        "    # Plot the input and output for X_test[0]\n",
        "    input_data = X_test[0]\n",
        "    output_data = model.predict(input_data.reshape(1, -1, 1)).flatten()  # Reshape to match the model input and flatten the output\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot the input data and output data as an overlay\n",
        "    plt.plot(input_data, label='Input')\n",
        "    plt.plot(output_data, label='Output', color='orange')\n",
        "    plt.title(f'Input and Output Data at Epoch {epoch}')\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the figure with a zero-padded filename for correct sorting\n",
        "    plt.savefig(f'output_epoch_{epoch:06d}.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Define the callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=reduce_lr_patience, min_lr=min_lr, verbose=1)\n",
        "# tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)\n",
        "custom_callback = CustomCallback(function=my_custom_function, frequency=10)\n",
        "\n",
        "\n",
        "# Fit the model with all callbacks\n",
        "with strategy.scope():\n",
        "    history = model.fit(\n",
        "        X_train, X_train,\n",
        "        epochs=10000,\n",
        "        batch_size=128,\n",
        "        validation_split=0.1,\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping, reduce_lr, custom_callback]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hiuoewm227G"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV3PibCJ2p3n"
      },
      "outputs": [],
      "source": [
        "# Function to save just the encoder part of the model\n",
        "def save_encoder_only(model, encoder_num_layers, embed_dim, save_path=root+name):\n",
        "    # Define a new input that matches the expected input shape of the encoder\n",
        "    encoder_input = model.input\n",
        "\n",
        "    # include patch embedding and reshape\n",
        "    x = model.get_layer(name=\"conv1d_patch_embedding\").output  # The Dense layer after reshaping\n",
        "    x = model.get_layer(name=\"global_avg_pooling\")(x)\n",
        "\n",
        "    # give positional embedding\n",
        "    num_patches = 10080 // patch_size\n",
        "    positional_embeddings = get_positional_embeddings(num_patches, embed_dim)\n",
        "\n",
        "    x = x + positional_embeddings\n",
        "\n",
        "    attention_weights = []\n",
        "    for i in range(encoder_num_layers):\n",
        "        transformer_block = model.get_layer(name=f\"encoder_layer_{i+1}_transformer\")\n",
        "        x, weights = transformer_block(x)\n",
        "        attention_weights.append(weights)\n",
        "\n",
        "    # Create the encoder model with the new input\n",
        "    encoder_model = models.Model(inputs=encoder_input, outputs=[x] + attention_weights, name=\"encoder_model\")\n",
        "    encoder_model.save(save_path)\n",
        "    print(f\"Encoder model saved to {save_path}\")\n",
        "\n",
        "# Save the encoder model\n",
        "save_encoder_only(model, encoder_num_layers, embed_dim=embed_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQoYh48E17Fz"
      },
      "outputs": [],
      "source": [
        "encoder_model = tf.keras.models.load_model(root+name, custom_objects={'TransformerBlock': TransformerBlock, 'get_positional_embeddings': get_positional_embeddings})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek3FFAV02Epd"
      },
      "outputs": [],
      "source": [
        "encoder_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObXfwpDYLRYs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "def plot_input_mask_output(model, X_test, num_samples=20, patch_size=patch_size):\n",
        "    \"\"\"\n",
        "    Creates a separate plot for each input from X_test, showing the original input,\n",
        "    the masked input that the model sees, the model's output, and a combination\n",
        "    of original and output data, stacked vertically.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained model.\n",
        "    - X_test: Test data, shape should be (num_samples, input_size, 1).\n",
        "    - num_samples: Number of samples to visualize.\n",
        "    - patch_size: Size of the patches used by the model.\n",
        "    \"\"\"\n",
        "    num_patches = X_test.shape[1] // patch_size\n",
        "\n",
        "    # Create a sub-model that outputs the visible patches and model output\n",
        "    intermediate_model = Model(inputs=model.input,\n",
        "                               outputs=[model.get_layer('mask_layer').output, model.output])\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        original_input = X_test[i].flatten()  # Flatten the original input for easy handling\n",
        "\n",
        "        # Get the intermediate output and final output from the model\n",
        "        mask_layer_output, model_output = intermediate_model.predict(X_test[i:i+1])\n",
        "        visible_patches, _, _, shuffle_indices, masked_indices = mask_layer_output\n",
        "\n",
        "\n",
        "        # Ensure the indices are properly interpreted as arrays\n",
        "        shuffle_indices = np.array(shuffle_indices)\n",
        "        masked_indices = np.array(masked_indices)\n",
        "\n",
        "        # Calculate the visible indices\n",
        "        visible_indices = np.setdiff1d(shuffle_indices, masked_indices)\n",
        "\n",
        "        # Combine the original and output data for the fourth plot\n",
        "        combined_data = original_input.copy()\n",
        "        model_output = model_output.flatten()\n",
        "        for idx in masked_indices:\n",
        "            start = idx * patch_size\n",
        "            end = start + patch_size\n",
        "            combined_data[start:end] = model_output[start:end]\n",
        "\n",
        "        # Create a new figure for each input\n",
        "        fig, axes = plt.subplots(4, 1, figsize=(30, 20))\n",
        "\n",
        "        # Plot original input\n",
        "        axes[0].plot(original_input, color='blue')\n",
        "        axes[0].set_title('Original Input')\n",
        "\n",
        "        # Plot the input and overlay gray highlight on non-visible patches\n",
        "        axes[1].plot(original_input, color='blue')\n",
        "        for idx in masked_indices:\n",
        "            start = idx * patch_size\n",
        "            end = start + patch_size\n",
        "            axes[1].axvspan(start, end, color='gray', zorder=10)  # Gray overlay in the foreground with high zorder\n",
        "        axes[1].set_title('Input with Non-Visible Patches Covered')\n",
        "\n",
        "        # Plot model output\n",
        "        axes[2].plot(original_input, color='lightgray', linestyle='dashed')\n",
        "        axes[2].plot(model_output, color='green')\n",
        "        axes[2].set_title('Model Output')\n",
        "\n",
        "        # Plot combined data with original input and light red background for masked areas\n",
        "        axes[3].plot(original_input, color='lightgray', linestyle='dashed')\n",
        "        for idx in masked_indices:\n",
        "            start = idx * patch_size\n",
        "            end = start + patch_size\n",
        "            axes[3].axvspan(start, end, color='lightcoral', alpha=1, zorder=1)  # Light red background\n",
        "        axes[3].plot(combined_data, color='green')\n",
        "        axes[3].set_title('Combined Data with Original and Masked Highlight')\n",
        "\n",
        "        # Adjust layout and show the plot\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKyVBu6rWLvF"
      },
      "outputs": [],
      "source": [
        "# Plot results\n",
        "plot_input_mask_output(model, X_test, patch_size=patch_size, num_samples=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWyaOsdInmqM"
      },
      "outputs": [],
      "source": [
        "#inspect the data rq"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}