{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DLnvDDAvZcg"
      },
      "source": [
        "# ALBERT Pretraining Notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luetswgMv_8y"
      },
      "source": [
        "Trained with Google TPU v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLBWYOLfN7Vt"
      },
      "source": [
        "#Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpupLYYoxvNH",
        "outputId": "e190bf55-01fd-4bf7-e16a-b7f71eb9dcc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gs2bFVn5ZMb",
        "outputId": "d7b0aaee-3eee-43f6-9997-a73cdcf50396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2.2.2)\n",
            "Collecting cramjam>=2.3 (from fastparquet)\n",
            "  Downloading cramjam-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2024.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
            "Downloading fastparquet-2024.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cramjam-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.8.4 fastparquet-2024.5.0\n"
          ]
        }
      ],
      "source": [
        "# @title Importing\n",
        "\n",
        "#Installs\n",
        "!pip install pyarrow fastparquet\n",
        "\n",
        "# Packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "#from keras.layers.embeddings import Embedding\n",
        "from keras.metrics import AUC\n",
        "\n",
        "# Tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afsH2qmUxGQi"
      },
      "outputs": [],
      "source": [
        "#@title Random Seeds\n",
        "import random\n",
        "## SEEDS\n",
        "\n",
        "# Hard Code Random Seeds.\n",
        "r1 = 0\n",
        "r2 = 1\n",
        "\n",
        "# Set Random Seed\n",
        "random.seed(r1)\n",
        "tf.random.set_seed(r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N4rQXYZcwz73",
        "outputId": "4757e382-c97d-44f6-bff0-75a536a42df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "TPU devices: [LogicalDevice(name='/device:TPU:0', device_type='TPU'), LogicalDevice(name='/device:TPU:1', device_type='TPU'), LogicalDevice(name='/device:TPU:2', device_type='TPU'), LogicalDevice(name='/device:TPU:3', device_type='TPU'), LogicalDevice(name='/device:TPU:4', device_type='TPU'), LogicalDevice(name='/device:TPU:5', device_type='TPU'), LogicalDevice(name='/device:TPU:6', device_type='TPU'), LogicalDevice(name='/device:TPU:7', device_type='TPU')]\n",
            "PerReplica:{\n",
            "  0: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  1: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  2: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  3: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  4: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  5: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  6: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  7: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#@title Connect to TPU\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Connect to the TPU cluster or fall back to CPU/GPU\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()  # Tries to connect to the TPU\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\n",
        "  devices = tf.config.list_logical_devices('TPU')\n",
        "  print('TPU devices:', devices)\n",
        "except ValueError:\n",
        "  print(\"Could not connect to TPU; using CPU/GPU strategy instead.\")\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "\n",
        "# Example computation using the strategy\n",
        "with strategy.scope():\n",
        "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "  @tf.function\n",
        "  def matmul_fn(x, y):\n",
        "    return tf.matmul(x, y)\n",
        "\n",
        "  z = strategy.run(matmul_fn, args=(a, b))\n",
        "\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6FAjx67HjgF"
      },
      "source": [
        "# Hyperparameters & Settings (Fill out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hgz3qjavw6xX"
      },
      "outputs": [],
      "source": [
        "# write where you want to save all your files\n",
        "root = \"/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/ALBERT Experiments /ALBERT Pretraining/Encoders\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM4cghQbLMn9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Please Fill out Parameters Below\n",
        "\"\"\"\n",
        "## Model size\n",
        "# eg. [\"small\", \"medium\", \"large\", \"huge\"]\n",
        "size = \"small\"\n",
        "\n",
        "## Mask ratio\n",
        "# eg. [.25, .50, .75]\n",
        "mask_ratio = 0.75\n",
        "\n",
        "## Smoothing\n",
        "# eg. [True, False]\n",
        "smoothing = False\n",
        "\n",
        "## Loss Function\n",
        "# eg. [True, False], meaning MSE on only the masked portion or everything in the reconstruction\n",
        "mse_only_masked = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XOvJcK73CeT"
      },
      "outputs": [],
      "source": [
        "# Model naming\n",
        "mask_name = int(mask_ratio*100)\n",
        "\n",
        "name = f\"/encoder_{size}_{mask_name}\"\n",
        "\n",
        "if smoothing == True:\n",
        "  name = f\"{name}_smoothed\"\n",
        "else:\n",
        "  name = f\"{name}_unsmoothed\"\n",
        "\n",
        "if mse_only_masked == True:\n",
        "  name = f\"{name}_mse_only_masked.h5\"\n",
        "else:\n",
        "  name = f\"{name}_mse_all.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4qslH7X3JKn",
        "outputId": "ca5358df-df1b-4e67-d23b-525ac46f617f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/encoder_small_75_unsmoothed_mse_only_masked.h5\n"
          ]
        }
      ],
      "source": [
        "print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ug9_cnGL0OT"
      },
      "source": [
        "# Hyperparameter Additional Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0rxwgR_HkrB"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Model Size\n",
        "\"\"\"\n",
        "## Model Size\n",
        "if size == \"small\":\n",
        "\n",
        "  patch_size = 18\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 6\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 1\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 6\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"medium\":\n",
        "\n",
        "  patch_size = 18\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 2\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"large\":\n",
        "\n",
        "  patch_size = 9\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 4\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"huge\":\n",
        "\n",
        "  patch_size = 5\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 8\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Eb0HHhsIUfM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "For Pretraining\n",
        "\"\"\"\n",
        "\n",
        "## Model Size\n",
        "if size == \"small\":\n",
        "\n",
        "  learning_rate = 0.001\n",
        "  early_stopping_patience = 250\n",
        "  reduce_lr_patience = 75\n",
        "  min_lr = 1e-4\n",
        "\n",
        "if size == \"medium\":\n",
        "\n",
        "  learning_rate = 0.001\n",
        "  early_stopping_patience = 250\n",
        "  reduce_lr_patience = 75\n",
        "  min_lr = 1e-4\n",
        "\n",
        "if size == \"large\":\n",
        "\n",
        "  learning_rate = 0.0001\n",
        "  early_stopping_patience = 500\n",
        "  reduce_lr_patience = 100\n",
        "  min_lr = 1e-5\n",
        "\n",
        "\n",
        "if size == \"huge\":\n",
        "\n",
        "  learning_rate = 0.00001\n",
        "  early_stopping_patience = 500\n",
        "  reduce_lr_patience = 100\n",
        "  min_lr = 1e-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHoK6hGwNJ6F"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Smoothing\n",
        "\"\"\"\n",
        "if smoothing == True:\n",
        "  data = pd.read_parquet('/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/Data Preprocessing/SelfSupervised Datasets/Smooth/[SelfSupervised][Smooth]WideSeqnActi_AndMeds_2013.parq')\n",
        "\n",
        "else:\n",
        "  data = pd.read_parquet('/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/Data Preprocessing/SelfSupervised Datasets/Raw/[SelfSupervised][Raw]WideSeqnActi_AndMeds_2013.parq')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye8xyruzvf68"
      },
      "source": [
        "# Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uzonweo6pYs"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First, split into train and temp (this temp will be split into validation and test)\n",
        "X_train, X_test = train_test_split(np.array(data), test_size=0.005, random_state=19, shuffle=True)\n",
        "\n",
        "\n",
        "# Reshape Train and Test\n",
        "n_participants_train = X_train.shape[0]\n",
        "n_participants_test = X_test.shape[0]\n",
        "n_timesteps = X_train.shape[1]\n",
        "n_features = 1\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((n_participants_train, n_timesteps, n_features))\n",
        "X_test = X_test.reshape((n_participants_test, n_timesteps, n_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2nSxPf9RBGs",
        "outputId": "54c07025-ddc9-48c6-9b84-7e41917a7b0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21430, 10080, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeMZYnkrRBOh",
        "outputId": "ed9ed7b2-ed54-4834-facd-3fa8d7ec1cc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108, 10080, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gT_O4t9zhBs"
      },
      "source": [
        "# Autoencoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1wPwVXe2KYC"
      },
      "source": [
        "#MAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu9PeUxXlFUT",
        "outputId": "4643effc-b654-47bf-e3fa-894a8ea8502a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"MAE_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " inputs (InputLayer)         [(None, 10080)]              0         []                            \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 560, 18)              0         ['inputs[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 560, 96)              1824      ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " mask_layer (MaskLayer)      ((None, 140, 96),            96        ['dense[0][0]']               \n",
            "                              (None, 420, 96),                                                    \n",
            "                              (140, 96),                                                          \n",
            "                              (560,),                                                             \n",
            "                              (420,))                                                             \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 140, 96)              0         ['mask_layer[0][0]',          \n",
            " Lambda)                                                             'mask_layer[0][2]']          \n",
            "                                                                                                  \n",
            " encoder_layer_1_transforme  [(None, None, 96),           272896    ['tf.__operators__.add[0][0]']\n",
            " r (Functional)               (None, 6, None, None)]                                              \n",
            "                                                                                                  \n",
            " mask_token_layer (MaskToke  (None, 420, 96)              0         ['mask_layer[0][1]']          \n",
            " nLayer)                                                                                          \n",
            "                                                                                                  \n",
            " concat_layer (ConcatLayer)  (None, 560, 96)              0         ['encoder_layer_1_transformer[\n",
            "                                                                    0][0]',                       \n",
            "                                                                     'mask_token_layer[0][0]']    \n",
            "                                                                                                  \n",
            " unshuffle_layer (Unshuffle  (None, 560, 96)              0         ['concat_layer[0][0]',        \n",
            " Layer)                                                              'mask_layer[0][3]']          \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TF  (None, 560, 96)              0         ['unshuffle_layer[0][0]']     \n",
            " OpLambda)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_layer_1_transforme  [(None, None, 96),           272896    ['tf.__operators__.add_3[0][0]\n",
            " r (Functional)               (None, 6, None, None)]                ']                            \n",
            "                                                                                                  \n",
            " decoder_dense (Dense)       (None, 560, 18)              1746      ['decoder_layer_1_transformer[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLamb  (None, 560, 18)              0         ['decoder_dense[0][0]']       \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_reshape (Reshape)   (None, 10080)                0         ['tf.math.multiply[0][0]']    \n",
            "                                                                                                  \n",
            " masked_mse_layer (MaskedMS  ()                           0         ['inputs[0][0]',              \n",
            " ELayer)                                                             'decoder_reshape[0][0]',     \n",
            "                                                                     'mask_layer[0][4]']          \n",
            "                                                                                                  \n",
            " add_loss (AddLoss)          ()                           0         ['masked_mse_layer[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 549458 (2.10 MB)\n",
            "Trainable params: 549458 (2.10 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Modified Transformer Block to output attention weights with explicit layer names\n",
        "def TransformerBlock(embed_dim, num_heads, ff_dim, rate=0.1, name_prefix=\"encoder\"):\n",
        "    # Input\n",
        "    input_layer = layers.Input(shape=(None, embed_dim), name=f\"{name_prefix}_input\")\n",
        "    #Attention\n",
        "    attention_layer = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, name=f\"{name_prefix}_attention\")\n",
        "    attention_output, attention_weights = attention_layer(input_layer, input_layer, return_attention_scores=True)\n",
        "    attention_output = layers.Dropout(rate, name=f\"{name_prefix}_dropout\")(attention_output)\n",
        "    # Add + Norm\n",
        "    out1 = layers.LayerNormalization(epsilon=1e-6, name=f\"{name_prefix}_norm1\")(input_layer + attention_output)\n",
        "    # FF Network\n",
        "    ff_output = layers.Dense(ff_dim, activation=\"relu\", name=f\"{name_prefix}_ff1\")(out1)\n",
        "    ff_output = layers.Dense(embed_dim, name=f\"{name_prefix}_ff2\")(ff_output)\n",
        "    ff_output = layers.Dropout(rate, name=f\"{name_prefix}_dropout2\")(ff_output)\n",
        "    # Add + Norm\n",
        "    final_output = layers.LayerNormalization(epsilon=1e-6, name=f\"{name_prefix}_norm2\")(out1 + ff_output)\n",
        "    return models.Model(inputs=input_layer, outputs=[final_output, attention_weights], name=f\"{name_prefix}_transformer\")\n",
        "\n",
        "# Custom Layer to create and apply the mask for MAE\n",
        "class MaskLayer(layers.Layer):\n",
        "    def __init__(self, mask_ratio, embed_dim, **kwargs):\n",
        "        super(MaskLayer, self).__init__(**kwargs)\n",
        "        self.mask_ratio = mask_ratio\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.mask_token = self.add_weight(\n",
        "            shape=(1, 1, self.embed_dim),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='mask_token'\n",
        "        )\n",
        "\n",
        "    def call(self, patch_embeddings, positional_embeddings):\n",
        "        batch_size = tf.shape(patch_embeddings)[0]\n",
        "        num_patches = tf.shape(patch_embeddings)[1]\n",
        "\n",
        "        shuffled_indices = tf.random.shuffle(tf.range(num_patches))\n",
        "        num_masked = tf.cast(tf.math.round(self.mask_ratio * tf.cast(num_patches, tf.float32)), tf.int32)\n",
        "\n",
        "        masked_indices = shuffled_indices[:num_masked]\n",
        "        visible_indices = shuffled_indices[num_masked:]\n",
        "\n",
        "        visible_patches = tf.gather(patch_embeddings, indices=visible_indices, axis=1)\n",
        "        masked_patches = tf.gather(patch_embeddings, indices=masked_indices, axis=1)\n",
        "        visible_positional_embeddings = tf.gather(positional_embeddings, indices=visible_indices, axis=0)\n",
        "\n",
        "        return visible_patches, masked_patches, visible_positional_embeddings, shuffled_indices, masked_indices\n",
        "\n",
        "# Custom Layer to create mask tokens for the decoder\n",
        "class MaskTokenLayer(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MaskTokenLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, mask_token, masked_patches):\n",
        "        tiled_mask_tokens = tf.tile(mask_token, [tf.shape(masked_patches)[0], tf.shape(masked_patches)[1], 1])\n",
        "        return tiled_mask_tokens\n",
        "\n",
        "# Custom Layer to concatenate tensors\n",
        "class ConcatLayer(layers.Layer):\n",
        "    def __init__(self, axis, **kwargs):\n",
        "        super(ConcatLayer, self).__init__(**kwargs)\n",
        "        self.axis = axis\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.concat(inputs, axis=self.axis)\n",
        "\n",
        "# Unshuffling Layer to revert the shuffle applied during masking\n",
        "class UnshuffleLayer(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(UnshuffleLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, patches, shuffle_indices):\n",
        "        num_patches = tf.shape(shuffle_indices)[0]\n",
        "\n",
        "        reverse_indices = tf.scatter_nd(\n",
        "            tf.expand_dims(shuffle_indices, axis=-1),\n",
        "            tf.range(num_patches),\n",
        "            [num_patches]\n",
        "        )\n",
        "\n",
        "        unshuffled_patches = tf.gather(patches, indices=reverse_indices, axis=1)\n",
        "\n",
        "        return unshuffled_patches\n",
        "\n",
        "# Sine/Cosine positional embeddings\n",
        "def get_positional_embeddings(num_patches, embed_dim):\n",
        "    position = tf.range(num_patches, dtype=tf.float32)[:, tf.newaxis]\n",
        "    div_term = tf.exp(tf.range(0, embed_dim, 2, dtype=tf.float32) * (-tf.math.log(10000.0) / embed_dim))\n",
        "    pos_embeddings = tf.concat([tf.sin(position * div_term), tf.cos(position * div_term)], axis=-1)\n",
        "    return pos_embeddings\n",
        "\n",
        "# Custom Layer to calculate MSE only on masked portions\n",
        "class MaskedMSELayer(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MaskedMSELayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, y_true, y_pred, masked_indices, mse_only_masked):\n",
        "\n",
        "        if mse_only_masked:\n",
        "            y_true_flat = tf.reshape(y_true, [-1])\n",
        "            y_pred_flat = tf.reshape(y_pred, [-1])\n",
        "\n",
        "            y_true_masked = tf.gather(y_true_flat, masked_indices)\n",
        "            y_pred_masked = tf.gather(y_pred_flat, masked_indices)\n",
        "\n",
        "            mse_loss = tf.reduce_mean(tf.square(y_true_masked - y_pred_masked))\n",
        "        else:\n",
        "            mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "        return mse_loss\n",
        "\n",
        "# Model creation function\n",
        "def create_model(input_size=10080, patch_size=patch_size, embed_dim=embed_dim,\n",
        "                 encoder_num_heads=encoder_num_heads, encoder_ff_dim=encoder_ff_dim, encoder_num_layers=encoder_num_layers, encoder_rate=encoder_rate,\n",
        "                 decoder_num_heads=decoder_num_heads, decoder_ff_dim=decoder_ff_dim, decoder_num_layers=decoder_num_layers, decoder_rate=decoder_rate,\n",
        "                 mask_ratio=mask_ratio, mse_only_masked=mse_only_masked, return_attention=False):\n",
        "\n",
        "    num_patches = input_size // patch_size\n",
        "    inputs = layers.Input(shape=(input_size,), name=\"inputs\")\n",
        "    reshaped = layers.Reshape((num_patches, patch_size), name=\"reshape\")(inputs)\n",
        "\n",
        "\n",
        "    patch_embeddings = layers.Dense(embed_dim, name=\"dense\")(reshaped)\n",
        "\n",
        "\n",
        "    positional_embeddings = get_positional_embeddings(num_patches, embed_dim)\n",
        "\n",
        "    mask_layer = MaskLayer(mask_ratio, embed_dim, name=\"mask_layer\")\n",
        "    visible_patches, masked_patches, visible_positional_embeddings, shuffle_indices, masked_indices = mask_layer(patch_embeddings, positional_embeddings)\n",
        "\n",
        "    x = visible_patches + visible_positional_embeddings\n",
        "    attention_weights = []\n",
        "\n",
        "    for i in range(encoder_num_layers):\n",
        "        x, weights = TransformerBlock(embed_dim, encoder_num_heads, encoder_ff_dim, encoder_rate, name_prefix=f\"encoder_layer_{i+1}\")(x)\n",
        "        if return_attention:\n",
        "            attention_weights.append(weights)\n",
        "\n",
        "    mask_token_layer = MaskTokenLayer(name=\"mask_token_layer\")\n",
        "    mask_tokens = mask_token_layer(mask_layer.mask_token, masked_patches)\n",
        "\n",
        "    decoder_input = ConcatLayer(axis=1, name=\"concat_layer\")([x, mask_tokens])\n",
        "\n",
        "    unshuffle_layer = UnshuffleLayer(name=\"unshuffle_layer\")\n",
        "    decoder_input_unshuffled = unshuffle_layer(decoder_input, shuffle_indices)\n",
        "\n",
        "    decoder_input_with_pos = decoder_input_unshuffled + positional_embeddings\n",
        "\n",
        "    y = decoder_input_with_pos\n",
        "    for i in range(decoder_num_layers):\n",
        "        y, _ = TransformerBlock(embed_dim, decoder_num_heads, encoder_ff_dim, decoder_rate, name_prefix=f\"decoder_layer_{i+1}\")(y)\n",
        "\n",
        "    outputs = layers.Dense(patch_size, activation='tanh', name=\"decoder_dense\")(y)\n",
        "    outputs = 2 * outputs #nothing above 2 standard deviations we'll just categorize as the same\n",
        "    outputs = layers.Reshape((input_size,), name=\"decoder_reshape\")(outputs)\n",
        "\n",
        "    masked_mse_layer = MaskedMSELayer(name=\"masked_mse_layer\")\n",
        "    loss = masked_mse_layer(inputs, outputs, masked_indices, mse_only_masked)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs, name=\"MAE_model\")\n",
        "    model.add_loss(loss)\n",
        "\n",
        "    if return_attention:\n",
        "        return models.Model(inputs=inputs, outputs=[outputs] + attention_weights, name=\"MAE_with_attention\")\n",
        "    else:\n",
        "        return model\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    model = create_model()\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "        learning_rate=learning_rate,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-07,\n",
        "        amsgrad=False))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNsm1XsL2wWq"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz_VsGkXeOJc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "\n",
        "# Define your custom callback\n",
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, function, frequency):\n",
        "        super(CustomCallback, self).__init__()\n",
        "        self.function = function\n",
        "        self.frequency = frequency\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.frequency == 0:\n",
        "            self.function(epoch + 1, logs)\n",
        "\n",
        "# Define your custom function\n",
        "def my_custom_function(epoch, logs):\n",
        "    print(f\"\\n plotting.. output {epoch}\")\n",
        "\n",
        "    # Plot the input and output for X_test[0]\n",
        "    input_data = X_test[0]\n",
        "    output_data = model.predict(input_data.reshape(1, -1, 1)).flatten()  # Reshape to match the model input and flatten the output\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot the input data and output data as an overlay\n",
        "    plt.plot(input_data, label='Input')\n",
        "    plt.plot(output_data, label='Output', color='orange')\n",
        "    plt.title(f'Input and Output Data at Epoch {epoch}')\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the figure with a zero-padded filename for correct sorting\n",
        "    plt.savefig(f'output_epoch_{epoch:06d}.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Define the callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=reduce_lr_patience, min_lr=min_lr, verbose=1)\n",
        "# tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)\n",
        "custom_callback = CustomCallback(function=my_custom_function, frequency=10)\n",
        "\n",
        "\n",
        "# Fit the model with all callbacks\n",
        "with strategy.scope():\n",
        "    history = model.fit(\n",
        "        X_train, X_train,\n",
        "        epochs=10000,\n",
        "        batch_size=128,\n",
        "        validation_split=0.1,\n",
        "        verbose=1,\n",
        "        callbacks=[early_stopping, reduce_lr, custom_callback]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hiuoewm227G"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV3PibCJ2p3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebe2b3f-1b1b-4583-a959-e3c8beade6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder model saved to /content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/ALBERT Experiments /ALBERT Pretraining/Encoders/encoder_small_75_unsmoothed_mse_only_masked.h5\n"
          ]
        }
      ],
      "source": [
        "# Function to save just the encoder part of the model\n",
        "def save_encoder_only(model, encoder_num_layers, embed_dim, save_path=root+name):\n",
        "    # Define a new input that matches the expected input shape of the encoder\n",
        "    encoder_input = model.input\n",
        "\n",
        "    # include patch embedding and reshape\n",
        "    x = model.get_layer(name=\"dense\").output  # The Dense layer after reshaping\n",
        "\n",
        "    # give positional embedding\n",
        "    num_patches = 10080 // patch_size\n",
        "    positional_embeddings = get_positional_embeddings(num_patches, embed_dim)\n",
        "\n",
        "    x = x + positional_embeddings\n",
        "\n",
        "    attention_weights = []\n",
        "    for i in range(encoder_num_layers):\n",
        "        transformer_block = model.get_layer(name=f\"encoder_layer_{i+1}_transformer\")\n",
        "        x, weights = transformer_block(x)\n",
        "        attention_weights.append(weights)\n",
        "\n",
        "    # Create the encoder model with the new input\n",
        "    encoder_model = models.Model(inputs=encoder_input, outputs=[x] + attention_weights, name=\"encoder_model\")\n",
        "    encoder_model.save(save_path)\n",
        "    print(f\"Encoder model saved to {save_path}\")\n",
        "\n",
        "# Save the encoder model\n",
        "save_encoder_only(model, encoder_num_layers, embed_dim=embed_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQoYh48E17Fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e453831-034a-4fb6-e7d1-e22f7a2c7058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "encoder_model = tf.keras.models.load_model(root+name, custom_objects={'TransformerBlock': TransformerBlock, 'get_positional_embeddings': get_positional_embeddings})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek3FFAV02Epd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2dad5c-32fa-4251-990b-73d714f06424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 10080)]           0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 560, 18)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 560, 96)           1824      \n",
            "                                                                 \n",
            " tf.__operators__.add_6 (TF  (None, 560, 96)           0         \n",
            " OpLambda)                                                       \n",
            "                                                                 \n",
            " encoder_layer_1_transforme  [(None, None, 96),        272896    \n",
            " r (Functional)               (None, 6, None, None)]             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 274720 (1.05 MB)\n",
            "Trainable params: 274720 (1.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObXfwpDYLRYs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "def plot_input_mask_output(model, X_test, num_samples=20, patch_size=patch_size):\n",
        "    \"\"\"\n",
        "    Creates a separate plot for each input from X_test, showing the original input,\n",
        "    the masked input that the model sees, the model's output, and a combination\n",
        "    of original and output data, stacked vertically.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained model.\n",
        "    - X_test: Test data, shape should be (num_samples, input_size, 1).\n",
        "    - num_samples: Number of samples to visualize.\n",
        "    - patch_size: Size of the patches used by the model.\n",
        "    \"\"\"\n",
        "    num_patches = X_test.shape[1] // patch_size\n",
        "\n",
        "    # Create a sub-model that outputs the visible patches and model output\n",
        "    intermediate_model = Model(inputs=model.input,\n",
        "                               outputs=[model.get_layer('mask_layer').output, model.output])\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        original_input = X_test[i].flatten()  # Flatten the original input for easy handling\n",
        "\n",
        "        # Get the intermediate output and final output from the model\n",
        "        mask_layer_output, model_output = intermediate_model.predict(X_test[i:i+1])\n",
        "        visible_patches, _, _, shuffle_indices, masked_indices = mask_layer_output\n",
        "\n",
        "\n",
        "        # Ensure the indices are properly interpreted as arrays\n",
        "        shuffle_indices = np.array(shuffle_indices)\n",
        "        masked_indices = np.array(masked_indices)\n",
        "\n",
        "        # Calculate the visible indices\n",
        "        visible_indices = np.setdiff1d(shuffle_indices, masked_indices)\n",
        "\n",
        "        # Combine the original and output data for the fourth plot\n",
        "        combined_data = original_input.copy()\n",
        "        model_output = model_output.flatten()\n",
        "        for idx in masked_indices:\n",
        "            start = idx * patch_size\n",
        "            end = start + patch_size\n",
        "            combined_data[start:end] = model_output[start:end]\n",
        "\n",
        "        # Create a new figure for each input\n",
        "        fig, axes = plt.subplots(4, 1, figsize=(30, 20))\n",
        "\n",
        "        # Plot original input\n",
        "        axes[0].plot(original_input, color='blue')\n",
        "        axes[0].set_title('Original Input')\n",
        "\n",
        "        # Plot the input and overlay gray highlight on non-visible patches\n",
        "        axes[1].plot(original_input, color='blue')\n",
        "        for idx in masked_indices:\n",
        "            start = idx * patch_size\n",
        "            end = start + patch_size\n",
        "            axes[1].axvspan(start, end, color='gray', zorder=10)  # Gray overlay in the foreground with high zorder\n",
        "        axes[1].set_title('Input with Non-Visible Patches Covered')\n",
        "\n",
        "        # Plot model output\n",
        "        axes[2].plot(original_input, color='lightgray', linestyle='dashed')\n",
        "        axes[2].plot(model_output, color='green')\n",
        "        axes[2].set_title('Model Output')\n",
        "\n",
        "        # Plot combined data with original input and light red background for masked areas\n",
        "        axes[3].plot(original_input, color='lightgray', linestyle='dashed')\n",
        "        for idx in masked_indices:\n",
        "            start = idx * patch_size\n",
        "            end = start + patch_size\n",
        "            axes[3].axvspan(start, end, color='lightcoral', alpha=1, zorder=1)  # Light red background\n",
        "        axes[3].plot(combined_data, color='green')\n",
        "        axes[3].set_title('Combined Data with Original and Masked Highlight')\n",
        "\n",
        "        # Adjust layout and show the plot\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKyVBu6rWLvF"
      },
      "outputs": [],
      "source": [
        "# Plot results\n",
        "plot_input_mask_output(model, X_test, patch_size=patch_size, num_samples=50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}