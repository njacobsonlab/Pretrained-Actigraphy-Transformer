{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DLnvDDAvZcg"
      },
      "source": [
        "# PAT Conv Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luetswgMv_8y"
      },
      "source": [
        "Trained with Google TPU v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLBWYOLfN7Vt"
      },
      "source": [
        "#Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpupLYYoxvNH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3Gs2bFVn5ZMb"
      },
      "outputs": [],
      "source": [
        "# @title Importing\n",
        "\n",
        "#Installs\n",
        "!pip install pyarrow fastparquet\n",
        "\n",
        "# Packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "#from keras.layers.embeddings import Embedding\n",
        "from keras.metrics import AUC\n",
        "\n",
        "# Tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afsH2qmUxGQi"
      },
      "outputs": [],
      "source": [
        "#@title Random Seeds\n",
        "import random\n",
        "## SEEDS\n",
        "\n",
        "# Hard Code Random Seeds.\n",
        "r1 = 0\n",
        "r2 = 1\n",
        "\n",
        "# Set Random Seed\n",
        "random.seed(r1)\n",
        "tf.random.set_seed(r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "N4rQXYZcwz73"
      },
      "outputs": [],
      "source": [
        "#@title Connect to TPU\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Connect to the TPU cluster or fall back to CPU/GPU\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()  # Tries to connect to the TPU\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\n",
        "  devices = tf.config.list_logical_devices('TPU')\n",
        "  print('TPU devices:', devices)\n",
        "except ValueError:\n",
        "  print(\"Could not connect to TPU; using CPU/GPU strategy instead.\")\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "\n",
        "# Example computation using the strategy\n",
        "with strategy.scope():\n",
        "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "  @tf.function\n",
        "  def matmul_fn(x, y):\n",
        "    return tf.matmul(x, y)\n",
        "\n",
        "  z = strategy.run(matmul_fn, args=(a, b))\n",
        "\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6FAjx67HjgF"
      },
      "source": [
        "# Hyperparameters & Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hgz3qjavw6xX"
      },
      "outputs": [],
      "source": [
        "# write where you want to save all your files and retrieve encoder\n",
        "root = \"/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/PAT Experiments /PAT Conv Finetuning/Models\"\n",
        "encoder_root = \"/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/PAT Experiments /PAT Conv Pretraining/Encoders\"\n",
        "results_root = \"/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/PAT Experiments /PAT Conv Finetuning/Results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM4cghQbLMn9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Please Fill out Parameters Below\n",
        "\"\"\"\n",
        "## Model size\n",
        "# eg. [\"small\", \"medium\", \"large\", \"huge\"]\n",
        "size = \"large\"\n",
        "\n",
        "## Mask ratio\n",
        "# eg. [.25, .50, .75]\n",
        "mask_ratio = 0.90\n",
        "\n",
        "## Smoothing\n",
        "# eg. [True, False]\n",
        "smoothing = False\n",
        "\n",
        "## Loss Function\n",
        "# eg. [True, False], meaning MSE on only the masked portion or everything in the reconstruction\n",
        "mse_only_masked = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN-fXaQZ_zA-"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Finetuning Specific Settings\n",
        "\"\"\"\n",
        "\n",
        "## Finetuning Styles\n",
        "# Add more if needed\n",
        "\n",
        "finetuning_styles = [\"full\", \"linear_probe\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ0wX2lh9I1o"
      },
      "outputs": [],
      "source": [
        "# Encoder naming\n",
        "mask_name = int(mask_ratio*100)\n",
        "\n",
        "encoder_name = f\"/conv_encoder_{size}_{mask_name}\"\n",
        "\n",
        "if smoothing == True:\n",
        "  encoder_name = f\"{encoder_name}_smoothed\"\n",
        "else:\n",
        "  encoder_name = f\"{encoder_name}_unsmoothed\"\n",
        "\n",
        "if mse_only_masked == True:\n",
        "  encoder_name = f\"{encoder_name}_mse_only_masked.h5\"\n",
        "else:\n",
        "  encoder_name = f\"{encoder_name}_mse_all.h5\"\n",
        "\n",
        "print(encoder_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lr8FC1YaoDB"
      },
      "outputs": [],
      "source": [
        "# Start of finetuning name\n",
        "ft_name = f\"/conv_AcT_{size}_{mask_name}\"\n",
        "\n",
        "if smoothing == True:\n",
        "  ft_name = f\"{ft_name}_smoothed\"\n",
        "else:\n",
        "  ft_name = f\"{ft_name}_unsmoothed\"\n",
        "\n",
        "if mse_only_masked == True:\n",
        "  ft_name = f\"{ft_name}_mse_only_masked\"\n",
        "else:\n",
        "  ft_name = f\"{ft_name}_mse_all\"\n",
        "\n",
        "print(ft_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B_fdXDFfWZK"
      },
      "outputs": [],
      "source": [
        "encoder_path = encoder_root + encoder_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ug9_cnGL0OT"
      },
      "source": [
        "# Hyperparameter Additional Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0rxwgR_HkrB"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Model Size\n",
        "\"\"\"\n",
        "## Model Size\n",
        "if size == \"small\":\n",
        "\n",
        "  patch_size = 18\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 6\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 1\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 6\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"medium\":\n",
        "\n",
        "  patch_size = 18\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 2\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"large\":\n",
        "\n",
        "  patch_size = 9\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 4\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"huge\":\n",
        "\n",
        "  patch_size = 5\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 8\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyWY0OzPKdxQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "For Finetuning\n",
        "\"\"\"\n",
        "\n",
        "## Model Size\n",
        "if size == \"small\":\n",
        "\n",
        "  learning_rate = 0.00001\n",
        "  early_stopping_patience = 250\n",
        "\n",
        "  reduce_lr_patience = 75\n",
        "  min_lr = 1e-6\n",
        "\n",
        "if size == \"medium\":\n",
        "\n",
        "  learning_rate = 0.00001\n",
        "  early_stopping_patience = 250\n",
        "\n",
        "  reduce_lr_patience = 75\n",
        "  min_lr = 1e-6\n",
        "\n",
        "if size == \"large\":\n",
        "\n",
        "  learning_rate = 0.000001\n",
        "  early_stopping_patience = 250\n",
        "\n",
        "  reduce_lr_patience = 75\n",
        "  min_lr = 1e-7\n",
        "\n",
        "\n",
        "if size == \"huge\":\n",
        "\n",
        "  learning_rate = 0.0000005\n",
        "  early_stopping_patience = 250\n",
        "\n",
        "  reduce_lr_patience = 100\n",
        "  min_lr = 1e-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lTk0F6CcxHI"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Smoothing\n",
        "\"\"\"\n",
        "if smoothing == True:\n",
        "  data_folder_location = \"/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/Baseline Tests/Data_2013/All_Meds/Smooth/TestSize2000_set1\"\n",
        "\n",
        "else:\n",
        "  data_folder_location = \"/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/Baseline Tests/Data_2013/All_Meds/Raw/TestSize2000_set1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye8xyruzvf68"
      },
      "source": [
        "# Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1OS8svAAbFY"
      },
      "outputs": [],
      "source": [
        "# Which sizes to look at\n",
        "train_sizes = [100, 250, 500, 1000, 2500, 5769] # for PAT hyperparameter tuning, we can test on less datasets\n",
        "test_size = 2000 # fixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia0lQCYwAjqH"
      },
      "outputs": [],
      "source": [
        "# first save the test sets\n",
        "X_test = np.load(os.path.join(data_folder_location, f'X_test_{test_size}.npy'))\n",
        "y_test = np.load(os.path.join(data_folder_location, f'y_test_{test_size}.npy'))\n",
        "\n",
        "\n",
        "# Scale the test set\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_test)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EctG1GkmHjXf"
      },
      "outputs": [],
      "source": [
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omax0tlpeIOn"
      },
      "outputs": [],
      "source": [
        "train_sets = {}\n",
        "val_sets = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rshy1g88eJsx"
      },
      "outputs": [],
      "source": [
        "for size in train_sizes:\n",
        "  X_train = np.load(os.path.join(data_folder_location, f'X_train_{size}.npy'))\n",
        "  y_train = np.load(os.path.join(data_folder_location, f'y_train_{size}.npy'))\n",
        "  train_sets[size] = (X_train, y_train)\n",
        "\n",
        "  X_val = np.load(os.path.join(data_folder_location, f'X_val_{size}.npy'))\n",
        "  y_val = np.load(os.path.join(data_folder_location, f'y_val_{size}.npy'))\n",
        "  val_sets[size] = (X_val, y_val)\n",
        "\n",
        "print(\"Data loaded successfully.\")\n",
        "print(f\"Train set size: {len(train_sets)}\")\n",
        "print(f\"Val set size: {len(val_sets)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIU90iu1eNYx"
      },
      "outputs": [],
      "source": [
        "for key, value in train_sets.items():\n",
        "  print(f\"For train size {key}: \")\n",
        "\n",
        "  # print the shapes of X train and y train\n",
        "  print(f\"X train shape: {value[0].shape}\")\n",
        "  print(f\"y train shape: {value[1].shape}\")\n",
        "\n",
        "  # also print the shapes of X val and y val\n",
        "  print(f\"X val shape: {val_sets[key][0].shape}\")\n",
        "  print(f\"y val shape: {val_sets[key][1].shape}\")\n",
        "\n",
        "  print(\"================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d02mit2U_t0y"
      },
      "source": [
        "# Wait for later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gT_O4t9zhBs"
      },
      "source": [
        "# LOAD PAT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu9PeUxXlFUT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Model\n",
        "\n",
        "# Modified Transformer Block to output attention weights with explicit layer names (otherwise the same as the )\n",
        "def TransformerBlock(embed_dim, num_heads, ff_dim, rate=0.1, name_prefix=\"encoder\"):\n",
        "    input_layer = layers.Input(shape=(None, embed_dim), name=f\"{name_prefix}_input\")\n",
        "    attention_layer = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, name=f\"{name_prefix}_attention\")\n",
        "    attention_output, attention_weights = attention_layer(input_layer, input_layer, return_attention_scores=True)\n",
        "    attention_output = layers.Dropout(rate, name=f\"{name_prefix}_dropout\")(attention_output)\n",
        "    out1 = layers.LayerNormalization(epsilon=1e-6, name=f\"{name_prefix}_norm1\")(input_layer + attention_output)\n",
        "    ff_output = layers.Dense(ff_dim, activation=\"relu\", name=f\"{name_prefix}_ff1\")(out1)\n",
        "    ff_output = layers.Dense(embed_dim, name=f\"{name_prefix}_ff2\")(ff_output)\n",
        "    ff_output = layers.Dropout(rate, name=f\"{name_prefix}_dropout2\")(ff_output)\n",
        "    final_output = layers.LayerNormalization(epsilon=1e-6, name=f\"{name_prefix}_norm2\")(out1 + ff_output)\n",
        "    return models.Model(inputs=input_layer, outputs=[final_output, attention_weights], name=f\"{name_prefix}_transformer\")\n",
        "\n",
        "# Sine/Cosine positional embeddings\n",
        "def get_positional_embeddings(num_patches, embed_dim):\n",
        "    position = tf.range(num_patches, dtype=tf.float32)[:, tf.newaxis]\n",
        "    div_term = tf.exp(tf.range(0, embed_dim, 2, dtype=tf.float32) * (-tf.math.log(10000.0) / embed_dim))\n",
        "    pos_embeddings = tf.concat([tf.sin(position * div_term), tf.cos(position * div_term)], axis=-1)\n",
        "    return pos_embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqtjZtr4o1Fo"
      },
      "outputs": [],
      "source": [
        "# Function to load the encoder and build the fine-tuning model with consistent patching and positional embedding\n",
        "def create_finetuning_model(encoder_path=encoder_path, input_size=10080, patch_size=patch_size, embed_dim=embed_dim, return_attention=False):\n",
        "\n",
        "    # Load the saved encoder model\n",
        "    encoder_model = tf.keras.models.load_model(encoder_path, custom_objects={'TransformerBlock': TransformerBlock, 'get_positional_embeddings': get_positional_embeddings})\n",
        "\n",
        "    # Define new inputs for the fine-tuning model\n",
        "    inputs = layers.Input(shape=(input_size,), name=\"finetuning_inputs\")\n",
        "\n",
        "    # Get encoder outputs\n",
        "    encoder_outputs = encoder_model(inputs)\n",
        "    encoder_outputs, attention_weights = encoder_outputs[0], encoder_outputs[1:]\n",
        "\n",
        "    # Pass through a GlobalAveragePooling layer\n",
        "    x = layers.GlobalAveragePooling1D(name=\"global_avg_pool\")(encoder_outputs)\n",
        "    x = layers.Dropout(0.1, name=\"dropout\")(x)\n",
        "    x = layers.Dense(128, activation='relu', name=\"dense_128\")(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n",
        "\n",
        "    # Include attention weights in the final model outputs if requested\n",
        "    if return_attention:\n",
        "        outputs = [outputs] + attention_weights\n",
        "\n",
        "    # Create and return the fine-tuning model\n",
        "    finetuning_model = models.Model(inputs=inputs, outputs=outputs, name=\"finetuning_model\")\n",
        "    return finetuning_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vI4lmYRg8BE"
      },
      "source": [
        "## Compiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gBQPBmsgyYE"
      },
      "outputs": [],
      "source": [
        "# Compile the model -----\n",
        "with strategy.scope():\n",
        "  train_model = create_finetuning_model(return_attention=False)\n",
        "  train_model.compile(\n",
        "    # Metrics\n",
        "    loss= tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    metrics= tf.keras.metrics.AUC(name='auc'),\n",
        "    # Optimizer\n",
        "    optimizer= tf.keras.optimizers.Adam(\n",
        "      learning_rate=learning_rate,\n",
        "      beta_1=0.9,\n",
        "      beta_2=0.999,\n",
        "      epsilon=1e-07,\n",
        "      amsgrad=False\n",
        "))\n",
        "\n",
        "# Save the original model weights\n",
        "train_model.save_weights('original_model_weights.h5')\n",
        "\n",
        "train_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpOx9Fi4I6e-"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "N8DF9BclK1D-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# # reduce learning rate (Don't use this it's buggy)\n",
        "# reduce_lr = ReduceLROnPlateau(\n",
        "#     monitor='val_loss',    # Monitor validation loss\n",
        "#     factor=0.5,            # Reduce rate by a factor of 0.5\n",
        "#     patience=75,           # Number of epochs with no improvement after which learning rate will be reduced\n",
        "#     min_lr=1e-6,           # Minimum learning rate that the reduction can reach\n",
        "#     verbose=1              # Print messages when reducing the learning rate\n",
        "# )\n",
        "\n",
        "# earlyStopping callback\n",
        "early_stopper = EarlyStopping(\n",
        "    monitor='val_auc',  # monitor validation AUC\n",
        "    mode='max',  # maximize AUC\n",
        "    patience=early_stopping_patience,  # number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,  # display messages when early stopping is triggered\n",
        "    restore_best_weights=True  # restore model weights from the epoch with the best value of the monitored quantity\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk6GQYtH6oJv"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "\n",
        "scores = {}\n",
        "scores[\"test\"] = {}\n",
        "scores[\"val\"] = {}\n",
        "\n",
        "for finetuning_style in finetuning_styles:\n",
        "  print(f\"\\nFinetuning Style: {finetuning_style}\")\n",
        "\n",
        "  scores[\"test\"][finetuning_style] = {}\n",
        "  scores[\"val\"][finetuning_style] = {}\n",
        "\n",
        "  for size in train_sizes:\n",
        "\n",
        "    print(f\"\\nSIZE:{size}\")\n",
        "\n",
        "\n",
        "    # Load X_train and fit\n",
        "    X_train, y_train = train_sets[size]\n",
        "    train_scalar = StandardScaler()\n",
        "    train_scalar.fit(X_train)\n",
        "    X_train = train_scalar.transform(X_train)\n",
        "\n",
        "    # Load X_val and fit\n",
        "    X_val, y_val = val_sets[size]\n",
        "    val_scalar = StandardScaler()\n",
        "    val_scalar.fit(X_val)\n",
        "    X_val = val_scalar.transform(X_val)\n",
        "\n",
        "    # Set Class Weights = Balance\n",
        "    class1 = sum(y_train)\n",
        "    total = len(y_train)\n",
        "    class0 = total-class1\n",
        "\n",
        "    class_weights = {0: (class1/total),\n",
        "                  1: ((class0/total))}\n",
        "\n",
        "    # Reset model weights\n",
        "    train_model.load_weights('original_model_weights.h5')\n",
        "\n",
        "    if finetuning_style == \"linear_probe\":\n",
        "      for layer in train_model.layers:\n",
        "        if layer.name == \"encoder_model\":\n",
        "            layer.trainable = False\n",
        "\n",
        "    if finetuning_style == \"full\":\n",
        "      for layer in train_model.layers:\n",
        "        layer.trainable = True\n",
        "\n",
        "    print(\" \")\n",
        "    # Verify by printing each layer's name and trainable status\n",
        "    for layer in train_model.layers:\n",
        "        print(layer.name, layer.trainable)\n",
        "    print(\" \")\n",
        "\n",
        "    # Train model\n",
        "    history = train_model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs= 10000, # Edit\n",
        "        batch_size= 64,\n",
        "        validation_data = (X_val, y_val),\n",
        "        shuffle=False,\n",
        "        class_weight=class_weights,\n",
        "        callbacks = [early_stopper],\n",
        "        verbose = 2)\n",
        "\n",
        "    # Save model\n",
        "    current_model_name = f\"{ft_name}_n{size}_{finetuning_style}.h5\"\n",
        "    print(current_model_name)\n",
        "    train_model.save(root+current_model_name)\n",
        "\n",
        "    # Test model\n",
        "    test_scores = train_model.evaluate(X_test, y_test, batch_size=64) # Test Set\n",
        "    scores[\"test\"][finetuning_style][size] = test_scores[1]\n",
        "    print(\"Test AUC:\", test_scores[1])\n",
        "\n",
        "    val_scores = train_model.evaluate(X_val, y_val, batch_size=64) # Val Set\n",
        "\n",
        "    scores[\"val\"][finetuning_style][size] = val_scores[1]\n",
        "    print(\"Val AUC:\", val_scores[1])\n",
        "\n",
        "# Save all results in a .txt\n",
        "print(\"\\n\\n\")\n",
        "print(scores)\n",
        "\n",
        "results_path = f\"{results_root}{ft_name}_RESULTS.txt\"\n",
        "\n",
        "try:\n",
        "    file_to_write = open(results_path, 'wt')\n",
        "    file_to_write.write(str(scores))\n",
        "    file_to_write.close()\n",
        "\n",
        "except:\n",
        "    print(\"Unable to write to file\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "FLBWYOLfN7Vt"
      ],
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}