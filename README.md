
# Is Attention All You Need For Actigraphy? Pre-trained Transformers for Wearable Accelerometer Data üèÉ‚Äç‚ôÄÔ∏èüèÉ

Abstract... blah blabh

# Tutorial/Demo Notebooks:
## ‚≠ê How to: Fine-tune ALBERT + How to use Built-in Model Explainability: https://colab.research.google.com/drive/1sub_5m6fV91GbqEOWT8Sl5RjwN2QnhNh?usp=sharing

This notebook will walk you through: 
* Setting up (importing/connecting to TPU)
* Loading Demo Data
* Loading Model
* Finetuning Model
* Evaluating Model
* Model Explainability 

You have to connect to TPUv2, or this will NOT work <be>  
In google colab, go to runtime->change runtime type <br>
Then select TPUv2 <br>
However, this should already be the default setting when you open the link.

## How to: Self-Supervised Pretraining: https://colab.research.google.com/drive/14VxoXzA374nNqYANI52rXbGuSW2ZAkxZ#scrollTo=_uzonweo6pYs

This notebook will walk you through: 
* Setting Up (importing/connecting to TPU)
* Choosing your Hyperparameters & Settings
* Loading Demo Data
* Loading Masked Autoencoder
* Training in a Self-Supervised Manner
* Saving only the model encoder
* Inspecting the autoencoder

## Attribution
Please cite our work if you use the code here. 
