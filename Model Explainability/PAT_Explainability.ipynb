{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PAT Explainability: Fill out to find what model you want to examine\n",
        "\n",
        "WARNING: For now you have to use TPU v2 to load the model"
      ],
      "metadata": {
        "id": "Oae7lAUNjsuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependencies\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "ptFS-I5_lOlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find what model you want and load that model"
      ],
      "metadata": {
        "id": "4N0pRXjOSNqu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkI0K0HqjBod"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Please Fill out Parameters Below\n",
        "\"\"\"\n",
        "## Model size\n",
        "# eg. [\"small\", \"medium\", \"large\", \"huge\"]\n",
        "size = \"large\"\n",
        "\n",
        "## Mask ratio\n",
        "# eg. [.25, .50, .75]\n",
        "mask_ratio = 0.90\n",
        "\n",
        "## Smoothing\n",
        "# eg. [True, False]\n",
        "smoothing = False\n",
        "\n",
        "## Loss Function\n",
        "# eg. [True, False], meaning MSE on only the masked portion or everything in the reconstruction\n",
        "mse_only_masked = False\n",
        "\n",
        "## dataset\n",
        "# eg. [\"n100\", \"n250\", etc]\n",
        "dataset = \"n5769\"\n",
        "\n",
        "## Finetuning Style\n",
        "# eg. [\"full\", \"linear_probe\"]\n",
        "finetuning_style = \"full\"\n",
        "\n",
        "## Where is this model located\n",
        "model_root = \"/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/PAT Experiments /PAT Finetuning/Models\"\n",
        "\n",
        "## Where the original encoder is from\n",
        "encoder_root = \"/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/PAT Experiments /PAT Pretraining/Encoders\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder naming\n",
        "mask_name = int(mask_ratio*100)\n",
        "\n",
        "encoder_name = f\"/encoder_{size}_{mask_name}\"\n",
        "\n",
        "if smoothing == True:\n",
        "  encoder_name = f\"{encoder_name}_smoothed\"\n",
        "else:\n",
        "  encoder_name = f\"{encoder_name}_unsmoothed\"\n",
        "\n",
        "if mse_only_masked == True:\n",
        "  encoder_name = f\"{encoder_name}_mse_only_masked.h5\"\n",
        "else:\n",
        "  encoder_name = f\"{encoder_name}_mse_all.h5\"\n",
        "\n",
        "print(encoder_name)"
      ],
      "metadata": {
        "id": "1G-HyvYJzsoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FT model name\n",
        "mask_name = int(mask_ratio*100)\n",
        "\n",
        "# Start of finetuning name\n",
        "ft_name = f\"/AcT_{size}_{mask_name}\"\n",
        "\n",
        "if smoothing == True:\n",
        "  ft_name = f\"{ft_name}_smoothed\"\n",
        "else:\n",
        "  ft_name = f\"{ft_name}_unsmoothed\"\n",
        "\n",
        "if mse_only_masked == True:\n",
        "  ft_name = f\"{ft_name}_mse_only_masked\"\n",
        "else:\n",
        "  ft_name = f\"{ft_name}_mse_all\"\n",
        "\n",
        "ft_name = f\"{ft_name}_{dataset}_{finetuning_style}.h5\"\n",
        "\n",
        "print(ft_name)"
      ],
      "metadata": {
        "id": "Ot-ZnrUYkQKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hyperparameter additional info"
      ],
      "metadata": {
        "id": "85UH49ylzFkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Model Size\n",
        "\"\"\"\n",
        "## Model Size\n",
        "if size == \"small\":\n",
        "\n",
        "  patch_size = 18\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 6\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 1\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 6\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"medium\":\n",
        "\n",
        "  patch_size = 18\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 2\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"large\":\n",
        "\n",
        "  patch_size = 9\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 4\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1\n",
        "\n",
        "if size == \"huge\":\n",
        "\n",
        "  patch_size = 5\n",
        "  embed_dim = 96\n",
        "  # encoder\n",
        "  encoder_num_heads = 12\n",
        "  encoder_ff_dim = 256\n",
        "  encoder_num_layers = 8\n",
        "  encoder_rate = 0.1\n",
        "  # decoder\n",
        "  decoder_num_heads = 12\n",
        "  decoder_ff_dim = 256\n",
        "  decoder_num_layers = 1\n",
        "  decoder_rate = 0.1"
      ],
      "metadata": {
        "id": "t61L5iLpzIO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Smoothing\n",
        "\"\"\"\n",
        "if smoothing == True:\n",
        "  data_folder_location = \"/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/Baseline Tests/Data_2013/All_Meds/Smooth/TestSize2000_set1\"\n",
        "\n",
        "else:\n",
        "  data_folder_location = \"/content/drive/MyDrive/Extra Curricular /ActigraphyTransformer/A-NEW/Baseline Tests/Data_2013/All_Meds/Raw/TestSize2000_set1\""
      ],
      "metadata": {
        "id": "Aebf4cqXxAuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b22I64EkxJS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load the encoder and build the fine-tuning model with consistent patching and positional embedding\n",
        "# Modified Transformer Block to output attention weights with explicit layer names (otherwise the same as the )\n",
        "def TransformerBlock(embed_dim, num_heads, ff_dim, rate=0.1, name_prefix=\"encoder\"):\n",
        "    input_layer = layers.Input(shape=(None, embed_dim), name=f\"{name_prefix}_input\")\n",
        "    attention_layer = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, name=f\"{name_prefix}_attention\")\n",
        "    attention_output, attention_weights = attention_layer(input_layer, input_layer, return_attention_scores=True)\n",
        "    attention_output = layers.Dropout(rate, name=f\"{name_prefix}_dropout\")(attention_output)\n",
        "    out1 = layers.LayerNormalization(epsilon=1e-6, name=f\"{name_prefix}_norm1\")(input_layer + attention_output)\n",
        "    ff_output = layers.Dense(ff_dim, activation=\"relu\", name=f\"{name_prefix}_ff1\")(out1)\n",
        "    ff_output = layers.Dense(embed_dim, name=f\"{name_prefix}_ff2\")(ff_output)\n",
        "    ff_output = layers.Dropout(rate, name=f\"{name_prefix}_dropout2\")(ff_output)\n",
        "    final_output = layers.LayerNormalization(epsilon=1e-6, name=f\"{name_prefix}_norm2\")(out1 + ff_output)\n",
        "    return models.Model(inputs=input_layer, outputs=[final_output, attention_weights], name=f\"{name_prefix}_transformer\")\n",
        "\n",
        "# Sine/Cosine positional embeddings\n",
        "def get_positional_embeddings(num_patches, embed_dim):\n",
        "    position = tf.range(num_patches, dtype=tf.float32)[:, tf.newaxis]\n",
        "    div_term = tf.exp(tf.range(0, embed_dim, 2, dtype=tf.float32) * (-tf.math.log(10000.0) / embed_dim))\n",
        "    pos_embeddings = tf.concat([tf.sin(position * div_term), tf.cos(position * div_term)], axis=-1)\n",
        "    return pos_embeddings\n",
        "\n",
        "def create_model(encoder_path=encoder_root+encoder_name, input_size=10080, patch_size=patch_size, embed_dim=embed_dim, return_attention=False):\n",
        "\n",
        "    # Load the saved encoder model\n",
        "    encoder_model = tf.keras.models.load_model(encoder_path, custom_objects={'TransformerBlock': TransformerBlock, 'get_positional_embeddings': get_positional_embeddings})\n",
        "\n",
        "    # Define new inputs for the fine-tuning model\n",
        "    inputs = layers.Input(shape=(input_size,), name=\"finetuning_inputs\")\n",
        "\n",
        "    # Get encoder outputs\n",
        "    encoder_outputs = encoder_model(inputs)\n",
        "    encoder_outputs, attention_weights = encoder_outputs[0], encoder_outputs[1:]\n",
        "\n",
        "    # Pass through a GlobalAveragePooling layer\n",
        "    x = layers.GlobalAveragePooling1D(name=\"global_avg_pool\")(encoder_outputs)\n",
        "    x = layers.Dropout(0.1, name=\"dropout\")(x)\n",
        "    x = layers.Dense(128, activation='relu', name=\"dense_128\")(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n",
        "\n",
        "    # Include attention weights in the final model outputs if requested\n",
        "    if return_attention:\n",
        "        outputs = [outputs] + attention_weights\n",
        "\n",
        "    # Create and return the fine-tuning model\n",
        "    finetuning_model = models.Model(inputs=inputs, outputs=outputs, name=\"finetuning_model\")\n",
        "    return finetuning_model"
      ],
      "metadata": {
        "id": "n88IOET9xwBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Once you have your model loaded this is all you need to do"
      ],
      "metadata": {
        "id": "xNTnMDJHS-Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model = create_model(return_attention=True)\n",
        "eval_model.summary()"
      ],
      "metadata": {
        "id": "0DGJvkOwxjQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model.load_weights(model_root+ft_name)"
      ],
      "metadata": {
        "id": "L1X_FRKK5t6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "3Y4mXZ3HTCnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 2000 # fixed\n",
        "# first save the test sets\n",
        "X_test = np.load(os.path.join(data_folder_location, f'X_test_{test_size}.npy'))\n",
        "y_test = np.load(os.path.join(data_folder_location, f'y_test_{test_size}.npy'))\n",
        "\n",
        "\n",
        "# Scale the test set\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_test)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "726fsD_dmKEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "rwVBlHecxSPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Attention Weights"
      ],
      "metadata": {
        "id": "jVXncb3TTDma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Graphing Functions\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "##### SQUARE PLOTTER -----------\n",
        "\n",
        "def plot_average_attention_weights(attention_weights, layer_num):\n",
        "    # Extract the weights for the specified layer\n",
        "    layer_weights = attention_weights[layer_num]  # Shape: (batch_size, num_heads, seq_length, seq_length)\n",
        "\n",
        "    # Compute the mean across all heads\n",
        "    mean_weights = np.mean(layer_weights, axis=1)  # Mean over the head dimension, resulting in (batch_size, seq_length, seq_length)\n",
        "\n",
        "    # Set the figure and specify its size\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))  # Adjust the figsize as needed to make the plot appear bigger\n",
        "\n",
        "    # Plotting the mean attention weights for the first sample in the batch using 'bwr' colormap\n",
        "    cax = ax.matshow(mean_weights[0], cmap='bwr')  # Index 0 for the first sample\n",
        "\n",
        "    # Create a colorbar with a smaller size\n",
        "    fig.colorbar(cax, fraction=0.046, pad=0.04)  # Adjust the fraction to make the colorbar thinner or thicker\n",
        "\n",
        "    ax.set_title(f'Layer {layer_num+1} Mean Attention Weights Across All Heads')\n",
        "    ax.set_xlabel('Key')\n",
        "    ax.set_ylabel('Query')\n",
        "    plt.show()\n",
        "\n",
        "#@title Function 2\n",
        "def process_attention_weights(attention_weights, layer_num, patch_size):\n",
        "    # Sum the attention weights across the key positions for each query position\n",
        "    attention_profile = np.sum(attention_weights[layer_num][0], axis=1)\n",
        "\n",
        "    # Average across heads\n",
        "    attention_profile = np.mean(attention_profile, axis=0)\n",
        "\n",
        "    # Normalize the attention profile to sum to 1\n",
        "    attention_profile /= np.sum(attention_profile)\n",
        "\n",
        "    # Expand the attention weights to match the original data's timeline\n",
        "    expanded_attention_profile = np.repeat(attention_profile, patch_size)\n",
        "\n",
        "    return expanded_attention_profile\n",
        "\n",
        "\n",
        "def plot_data_with_attention_overlay_7d(original_data, attention_weights, layer_num, patch_size):\n",
        "    # Process the attention weights\n",
        "    processed_attention_profile = process_attention_weights(attention_weights, layer_num, patch_size)\n",
        "\n",
        "    # Create a colormap based on the processed attention weights\n",
        "    cmap = plt.cm.seismic\n",
        "    norm = mcolors.Normalize(vmin=processed_attention_profile.min(), vmax=processed_attention_profile.max())\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 4))\n",
        "\n",
        "    # Plot the original data\n",
        "    ax1.plot(original_data, label='Original Data', color='black')\n",
        "    ax1.set_xlabel('Time (minutes)')\n",
        "    ax1.set_ylabel('Original Data Value', color='blue')\n",
        "    ax1.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "    # Set up x-axis for daily ticks and labels\n",
        "    days = ['Day 1', 'Day 2', 'Day 3', 'Day 4', 'Day 5', 'Day 6', 'Day 7']\n",
        "    minutes_per_day = 1440\n",
        "    week_minutes = minutes_per_day * len(days)\n",
        "    day_starts = np.arange(0, week_minutes, minutes_per_day)\n",
        "    ax1.set_xticks(day_starts)\n",
        "    ax1.set_xticklabels(days, rotation=45)\n",
        "    ax1.set_xlim([0, week_minutes])\n",
        "\n",
        "    # Create a twin Axes sharing the x-axis to plot the attention weights\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    # Plot the attention as a background colormap\n",
        "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "    sm.set_array([])  # Only needed for older versions of matplotlib\n",
        "    ax2.imshow([processed_attention_profile], aspect='auto', extent=[0, len(original_data), ax1.get_ylim()[0], ax1.get_ylim()[1]], cmap=cmap, norm=norm, alpha=0.3)\n",
        "    ax2.set_yticks([])\n",
        "    ax2.set_yticklabels([])\n",
        "\n",
        "    # Add a colorbar for the attention overlay\n",
        "    cbar = plt.colorbar(sm, ax=ax2, pad=0.1, aspect=10)\n",
        "    cbar.set_label('Attention Weight', rotation=270, labelpad=15)\n",
        "\n",
        "    fig.tight_layout()  # To ensure no overlap of y-ticks\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#@title Function 3\n",
        "\n",
        "def downsample_to_daily(data, days=7, minutes_per_day=1440):\n",
        "    # Reshape the data to (days, minutes_per_day)\n",
        "    reshaped_data = data.reshape((days, minutes_per_day))\n",
        "    # Calculate the mean across days for each minute\n",
        "    daily_mean_data = reshaped_data.mean(axis=0)\n",
        "    return daily_mean_data\n",
        "\n",
        "\n",
        "def plot_data_with_attention_overlay_1day(original_data, attention_weights, layer_num, patch_size):\n",
        "    # Process the attention weights\n",
        "    processed_attention_profile = process_attention_weights(attention_weights, layer_num, patch_size)\n",
        "\n",
        "    # Downsample both the original data and the attention profile to a daily scale\n",
        "    daily_original_data = downsample_to_daily(original_data)\n",
        "    daily_attention_profile = downsample_to_daily(processed_attention_profile)\n",
        "\n",
        "    # Create a colormap based on the processed attention weights\n",
        "    cmap = plt.cm.bwr\n",
        "    norm = mcolors.Normalize(vmin=daily_attention_profile.min(), vmax=daily_attention_profile.max())\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 4))\n",
        "\n",
        "    # Plot the downsampled original data\n",
        "    ax1.plot(daily_original_data, label='Daily Mean Original Data', color='black')\n",
        "    ax1.set_xlabel('Time (hours)')\n",
        "    ax1.set_ylabel('Daily Mean Original Data Value', color='black')\n",
        "    ax1.tick_params(axis='y', labelcolor='black')\n",
        "\n",
        "    # Define custom tick positions and labels for hours\n",
        "    hours = np.arange(0, 25, 3)  # Hours from 0 to 24\n",
        "    minutes_per_hour = 60\n",
        "    hour_positions = hours * minutes_per_hour\n",
        "    hour_labels = [f'{hour:02d}:00' for hour in hours]\n",
        "    ax1.set_xticks(hour_positions)\n",
        "    ax1.set_xticklabels(hour_labels)\n",
        "\n",
        "    # Create a twin Axes sharing the x-axis to plot the attention weights\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    # Plot the attention as a background colormap\n",
        "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "    sm.set_array([])  # Only needed for older versions of matplotlib\n",
        "    minutes_per_day = 1440\n",
        "    ax2.imshow([daily_attention_profile], aspect='auto', extent=[0, minutes_per_day, ax1.get_ylim()[0], ax1.get_ylim()[1]], cmap=cmap, norm=norm, alpha=0.5)\n",
        "    ax2.set_yticks([])\n",
        "    ax2.set_yticklabels([])\n",
        "\n",
        "    # Add a colorbar for the attention overlay\n",
        "    cbar = plt.colorbar(sm, ax=ax2, pad=0.1, aspect=10)\n",
        "    cbar.set_label('Attention Weight', rotation=270, labelpad=15)\n",
        "\n",
        "    fig.tight_layout()  # To ensure no overlap of y-ticks\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "V8BW3vlR6RMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for control patients\n",
        "i = 0\n",
        "total = 0\n",
        "for participant in y_test:\n",
        "\n",
        "  # only plot for 50 participants\n",
        "  if i == 50:\n",
        "    break\n",
        "\n",
        "  # if they are in the control group\n",
        "  if participant != 1:\n",
        "    i+=1  #increase plotted number of participants\n",
        "    # get the attention weights\n",
        "    predictions, *att_weights = eval_model.predict(X_test[total:total+1])\n",
        "    a = scaler.inverse_transform([X_test[total].reshape(10080,)]).reshape(10080,1)\n",
        "\n",
        "    # Make All The PLOTS\n",
        "    print(\"=====================================================\")\n",
        "    print(\"CONTROL PARTICIPANT: \" + str(total+1))\n",
        "    print(\"=====================================================\")\n",
        "    plot_average_attention_weights(att_weights, encoder_num_layers-1)\n",
        "    plot_data_with_attention_overlay_7d(a, att_weights, encoder_num_layers-1, patch_size)\n",
        "    plot_data_with_attention_overlay_1day(a, att_weights, encoder_num_layers-1, patch_size)\n",
        "  total += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "cRE1TQpb6Y_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for exp patients\n",
        "i = 0\n",
        "total = 0\n",
        "for participant in y_test:\n",
        "\n",
        "  # only plot for 50 participants\n",
        "  if i == 50:\n",
        "    break\n",
        "\n",
        "  # if they are in the control group\n",
        "  if participant == 1:\n",
        "    i+=1  #increase plotted number of participants\n",
        "    # get the attention weights\n",
        "    predictions, *att_weights = eval_model.predict(X_test[total:total+1])\n",
        "    a = scaler.inverse_transform([X_test[total].reshape(10080,)]).reshape(10080,1)\n",
        "\n",
        "    # Make All The PLOTS\n",
        "    print(\"=====================================================\")\n",
        "    print(\"NOT CONTROL PARTICIPANT: \" + str(total+1))\n",
        "    print(\"=====================================================\")\n",
        "    plot_average_attention_weights(att_weights, encoder_num_layers-1)\n",
        "    plot_data_with_attention_overlay_7d(a, att_weights, encoder_num_layers-1, patch_size)\n",
        "    plot_data_with_attention_overlay_1day(a, att_weights, encoder_num_layers-1, patch_size)\n",
        "  total += 1"
      ],
      "metadata": {
        "id": "DYwIq-zHjDhq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
